{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5c2d3-db8c-4871-979f-92089c4b2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pipeline.ipynb\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "def get_best_model(goal_acc: float = 0.50,\n",
    "                   experiment_name: str = \"tutorial_model\") \\\n",
    "        -> NamedTuple('BestModel', [('version', float), ('acc', float)]):\n",
    "    import kfp\n",
    "    import os\n",
    "\n",
    "    os.environ[\"KF_PIPELINES_ENDPOINT\"] = \"http://ml-pipeline.kubeflow.svc.cluster.local:8888\"\n",
    "\n",
    "    kfp_proxy_host = os.environ[\"KFP_PROXY_SERVICE_HOST\"]\n",
    "    kfp_proxy_port = os.environ[\"KFP_PROXY_SERVICE_PORT\"]\n",
    "\n",
    "    client = kfp.Client(proxy=f\"http://{kfp_proxy_host}:{kfp_proxy_port}\")\n",
    "    #client = kfp.Client()\n",
    "\n",
    "    experiment = client.get_experiment(experiment_name=experiment_name)\n",
    "    list_runs = client.list_runs(experiment_id=experiment.id,\n",
    "                                 page_size=0)\n",
    "    runs = list_runs.runs\n",
    "\n",
    "    best_model = {'path': 'None', 'acc': goal_acc}\n",
    "    for run in runs:\n",
    "\n",
    "        run_dict = run.to_dict()\n",
    "        if run_dict['storage_state'] == 'STORAGESTATE_ARCHIVED':\n",
    "            continue\n",
    "        if run_dict['metrics'] is None:\n",
    "            continue\n",
    "        if run_dict['status'] != 'Succeeded':\n",
    "            continue\n",
    "        if run_dict['pipeline_spec']['parameters'] is None:\n",
    "            continue     \n",
    "   \n",
    "        model = {'version': run_dict['metrics'][0]['number_value'],\n",
    "                 'acc': run_dict['metrics'][1]['number_value']}\n",
    "        if best_model['acc'] < model['acc']:\n",
    "            best_model = model\n",
    "    print(best_model)\n",
    "\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('BestModel', ['version', 'acc'])\n",
    "\n",
    "    return result(best_model['version'], best_model['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2d149-eb6b-4194-b4f5-cb4263f3cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_dataset(data_path: str) -> str:\n",
    "    import fnmatch\n",
    "    import numpy as np\n",
    "    import os    \n",
    "    files = fnmatch.filter(os.listdir(data_path), '*.npz')\n",
    "    files.sort(key=lambda fn: os.path.getmtime(os.path.join(data_path, fn)))\n",
    "    return os.path.join(data_path, files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9536d-ea6d-457d-baab-ca32f5b2a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pipeline.ipynb\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "def train_from_best_model(model_version: float,\n",
    "                          new_dataset_path: str) \\\n",
    "        -> NamedTuple('Outputs', [('mlpipeline_metrics', 'Metrics'), \n",
    "                                  ('model_version', float)]):\n",
    "    import datetime\n",
    "    import time\n",
    "    import json\n",
    "    import os\n",
    "    import shutil\n",
    "    from kubeflow import katib\n",
    "    from kubeflow.katib import KatibClient\n",
    "\n",
    "    from kubernetes.client import V1ObjectMeta\n",
    "    from kubeflow.katib import V1beta1Experiment\n",
    "    from kubeflow.katib import V1beta1AlgorithmSpec\n",
    "    from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "    from kubeflow.katib import V1beta1FeasibleSpace\n",
    "    from kubeflow.katib import V1beta1ExperimentSpec\n",
    "    from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "    from kubeflow.katib import V1beta1ParameterSpec\n",
    "    from kubeflow.katib import V1beta1TrialTemplate\n",
    "    from kubeflow.katib import V1beta1TrialParameterSpec\n",
    "\n",
    "    def find_metrics(_list, name, _type):\n",
    "        return next(filter(lambda _list: _list['name'] == name, _list))[_type]\n",
    "    \n",
    "    def move_dataset(orig_path):\n",
    "        target_dir = \"/notebook/new_dataset/retrain\"\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        npz = os.path.basename(orig_path)\n",
    "        shutil.copy(orig_path, f'{target_dir}/{npz}')\n",
    "\n",
    "    kclient = KatibClient()\n",
    "    kclient.list_experiments()\n",
    "    date_postfix = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    experiment_name = f\"my-model-retrain-{date_postfix}\"\n",
    "    objective_metric_name = \"Validation-accuracy\"\n",
    "\n",
    "    metadata = V1ObjectMeta(\n",
    "        name=experiment_name\n",
    "    )\n",
    "\n",
    "    algorithm_spec = V1beta1AlgorithmSpec(\n",
    "        algorithm_name=\"random\"\n",
    "    )\n",
    "\n",
    "    objective_spec = V1beta1ObjectiveSpec(\n",
    "        type=\"maximize\",\n",
    "        goal=0.99,\n",
    "        objective_metric_name=objective_metric_name,\n",
    "        additional_metric_names=[\"Validation-loss\", \"accuracy\", \"loss\"]\n",
    "    )\n",
    "\n",
    "    parameters = [\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"epoch\",\n",
    "            parameter_type=\"int\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                min=\"10\",\n",
    "                max=\"30\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    dt_now = datetime.datetime.now()\n",
    "    save_version = dt_now.strftime('%Y%m%d%H%M%S')\n",
    "    # JSON template specification for the Trial's Worker Kubernetes Job.\n",
    "    trial_spec = {\n",
    "        \"apiVersion\": \"batch/v1\",\n",
    "        \"kind\": \"Job\",\n",
    "        \"spec\": {\n",
    "            \"template\": {\n",
    "                \"metadata\": {\n",
    "                    \"annotations\": {\n",
    "                        \"sidecar.istio.io/inject\": \"false\"\n",
    "                    }\n",
    "                },\n",
    "                \"spec\": {\n",
    "                    \"containers\": [\n",
    "                        {\n",
    "                            \"name\": \"training-container\",\n",
    "                            \"image\": \"yourID/fashion-mnist-retrain:handson\", \n",
    "                            \"imagePullPolicy\": \"Always\",\n",
    "                            \"volumeMounts\": [\n",
    "                                {\"name\": \"notebook\", \"mountPath\": \"/notebook\"},\n",
    "                            ],\n",
    "                            \"command\": [\n",
    "                                \"python\",\n",
    "                                \"/app/my_model_retrain.py\",\n",
    "                                \"--node_amount=${trialParameters.epoch}\",\n",
    "                                f\"--dataset_path={new_dataset_path}\",\n",
    "                                f\"--model_path=/notebook/model/\",\n",
    "                                f\"--train_version={model_version}\",\n",
    "                                f\"--save_version={save_version}\"\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \"restartPolicy\": \"Never\",\n",
    "                    \"volumes\": [\n",
    "                        {\"name\": \"notebook\",\n",
    "                         \"persistentVolumeClaim\": {\"claimName\": \"workspace-handson\"}\n",
    "                         }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Configure parameters for the Trial template.\n",
    "    trial_template = V1beta1TrialTemplate(\n",
    "        primary_container_name=\"training-container\",\n",
    "        trial_parameters=[\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"epoch\",\n",
    "                description=\"train epoch\",\n",
    "                reference=\"epoch\"\n",
    "            ),\n",
    "        ],\n",
    "        trial_spec=trial_spec\n",
    "    )\n",
    "\n",
    "    # Experiment object.\n",
    "    experiment = V1beta1Experiment(\n",
    "        api_version=\"kubeflow.org/v1beta1\",\n",
    "        kind=\"Experiment\",\n",
    "        metadata=metadata,\n",
    "        spec=V1beta1ExperimentSpec(\n",
    "            max_trial_count=3,\n",
    "            parallel_trial_count=3,\n",
    "            max_failed_trial_count=3,\n",
    "            algorithm=algorithm_spec,\n",
    "            objective=objective_spec,\n",
    "            parameters=parameters,\n",
    "            resume_policy=None,\n",
    "            trial_template=trial_template,\n",
    "        )\n",
    "    )\n",
    "    kclient.create_experiment(experiment)\n",
    "    accuracy = 0.0\n",
    "    while 1:\n",
    "        time.sleep(60)\n",
    "        status = kclient.get_experiment_status(experiment_name)\n",
    "        result = kclient.get_optimal_hyperparameters(experiment_name)\n",
    "        if status == \"Running\":\n",
    "            print(f\"{experiment_name} is running\")\n",
    "        if status == \"Succeeded\":\n",
    "            if result:\n",
    "                metrics = result['currentOptimalTrial']['observation']['metrics']\n",
    "                val_acc = find_metrics(metrics, objective_metric_name, 'max')\n",
    "            move_dataset(new_dataset_path)                \n",
    "            break\n",
    "\n",
    "    metrics = {\n",
    "        'metrics': [{\n",
    "            'name': 'val-acc',\n",
    "            'numberValue': float(val_acc),\n",
    "            'format': \"PERCENTAGE\",\n",
    "        },{\n",
    "            'name': 'model-version',\n",
    "            'numberValue': float(save_version) + float(val_acc[:4]),\n",
    "            'format': \"RAW\",\n",
    "        }]\n",
    "    }\n",
    "    from collections import namedtuple    \n",
    "    result = namedtuple('Outputs', ['mlpipeline_metrics', 'model_version'])    \n",
    "    return result(json.dumps(metrics), model_version)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4e10d-6636-43d7-b00c-fc3edb81ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pipeline.ipynb\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op\n",
    "\n",
    "\n",
    "def disable_cache(op):\n",
    "    op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "\n",
    "def container_op(func):\n",
    "    return func_to_container_op(func,\n",
    "                                base_image=\"dudaji/cap-jupyterlab:tf2.0-cpu\")\n",
    "\n",
    "def train_pipeline(goal_acc: float = 0.50,\n",
    "                   dataset_path: str = \"/notebook/new_dataset/train\"):\n",
    "    notebook_vol = dsl.PipelineVolume(pvc=\"workspace-handson\")\n",
    "\n",
    "    model_op = container_op(get_best_model)\n",
    "    dataset_op = container_op(get_last_dataset)\n",
    "    train_op = container_op(train_from_best_model)\n",
    "\n",
    "    model_comp = model_op(goal_acc) \\\n",
    "        .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "\n",
    "    dataset_comp = dataset_op(dataset_path) \\\n",
    "        .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "\n",
    "    train_comp = train_op(model_version=model_comp.outputs['version'],\n",
    "                          new_dataset_path=dataset_comp.output) \\\n",
    "        .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "                          \n",
    "    disable_cache(dataset_comp)                          \n",
    "    disable_cache(model_comp)                          \n",
    "    disable_cache(train_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f8d93-073c-4b29-bbb3-73df32c6246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pipeline.ipynb\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "def get_best_model(goal_acc: float = 0.50,\n",
    "                   experiment_name: str = \"tutorial_model\") \\\n",
    "        -> NamedTuple('BestModel', [('version', float), ('acc', float)]):\n",
    "    import kfp\n",
    "    import os\n",
    "\n",
    "    os.environ[\"KF_PIPELINES_ENDPOINT\"] = \"http://ml-pipeline.kubeflow.svc.cluster.local:8888\"\n",
    "\n",
    "    kfp_proxy_host = os.environ[\"KFP_PROXY_SERVICE_HOST\"]\n",
    "    kfp_proxy_port = os.environ[\"KFP_PROXY_SERVICE_PORT\"]\n",
    "\n",
    "    client = kfp.Client(proxy=f\"http://{kfp_proxy_host}:{kfp_proxy_port}\")\n",
    "    #client = kfp.Client()\n",
    "\n",
    "    experiment = client.get_experiment(experiment_name=experiment_name)\n",
    "    list_runs = client.list_runs(experiment_id=experiment.id,\n",
    "                                 page_size=0)\n",
    "    runs = list_runs.runs\n",
    "\n",
    "    best_model = {'path': 'None', 'acc': goal_acc}\n",
    "    for run in runs:\n",
    "\n",
    "        run_dict = run.to_dict()\n",
    "        if run_dict['storage_state'] == 'STORAGESTATE_ARCHIVED':\n",
    "            continue\n",
    "        if run_dict['metrics'] is None:\n",
    "            continue\n",
    "        if run_dict['status'] != 'Succeeded':\n",
    "            continue\n",
    "        if run_dict['pipeline_spec']['parameters'] is None:\n",
    "            continue     \n",
    "   \n",
    "        model = {'version': run_dict['metrics'][0]['number_value'],\n",
    "                 'acc': run_dict['metrics'][1]['number_value']}\n",
    "        if best_model['acc'] < model['acc']:\n",
    "            best_model = model\n",
    "    print(best_model)\n",
    "\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('BestModel', ['version', 'acc'])\n",
    "\n",
    "    return result(best_model['version'], best_model['acc'])\n",
    "\n",
    "\n",
    "def get_last_dataset(dataset_path: str) -> str:\n",
    "    import fnmatch\n",
    "    import numpy as np\n",
    "    import os    \n",
    "    files = fnmatch.filter(os.listdir(dataset_path), '*.npz')\n",
    "    files.sort(key=lambda fn: os.path.getmtime(os.path.join(dataset_path, fn)))\n",
    "    last_dataset = os.path.join(dataset_path, files[1])\n",
    "    print(last_dataset)\n",
    "    return last_dataset\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "def train_from_best_model(model_version: float,\n",
    "                          new_dataset_path: str) \\\n",
    "        -> NamedTuple('Outputs', [('mlpipeline_metrics', 'Metrics'), \n",
    "                                  ('model_version', str)]):\n",
    "    import datetime\n",
    "    import time\n",
    "    import json\n",
    "    import os\n",
    "    import shutil\n",
    "    from kubeflow import katib\n",
    "    from kubeflow.katib import KatibClient\n",
    "\n",
    "    from kubernetes.client import V1ObjectMeta\n",
    "    from kubeflow.katib import V1beta1Experiment\n",
    "    from kubeflow.katib import V1beta1AlgorithmSpec\n",
    "    from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "    from kubeflow.katib import V1beta1FeasibleSpace\n",
    "    from kubeflow.katib import V1beta1ExperimentSpec\n",
    "    from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "    from kubeflow.katib import V1beta1ParameterSpec\n",
    "    from kubeflow.katib import V1beta1TrialTemplate\n",
    "    from kubeflow.katib import V1beta1TrialParameterSpec\n",
    "\n",
    "    def find_metrics(_list, name, _type):\n",
    "        return next(filter(lambda _list: _list['name'] == name, _list))[_type]\n",
    "    \n",
    "    def move_dataset(orig_path):\n",
    "        target_dir = \"/notebook/new_dataset/retrain\"\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        npz = os.path.basename(orig_path)\n",
    "        shutil.copy(orig_path, f'{target_dir}/{npz}')\n",
    "\n",
    "    kclient = KatibClient()\n",
    "    kclient.list_experiments()\n",
    "    date_postfix = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    experiment_name = f\"my-model-retrain-{date_postfix}\"\n",
    "    objective_metric_name = \"Validation-accuracy\"\n",
    "\n",
    "    metadata = V1ObjectMeta(\n",
    "        name=experiment_name\n",
    "    )\n",
    "\n",
    "    algorithm_spec = V1beta1AlgorithmSpec(\n",
    "        algorithm_name=\"random\"\n",
    "    )\n",
    "\n",
    "    objective_spec = V1beta1ObjectiveSpec(\n",
    "        type=\"maximize\",\n",
    "        goal=0.99,\n",
    "        objective_metric_name=objective_metric_name,\n",
    "        additional_metric_names=[\"Validation-loss\", \"accuracy\", \"loss\"]\n",
    "    )\n",
    "\n",
    "    parameters = [\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"epoch\",\n",
    "            parameter_type=\"int\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                min=\"10\",\n",
    "                max=\"30\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # JSON template specification for the Trial's Worker Kubernetes Job.\n",
    "    trial_spec = {\n",
    "        \"apiVersion\": \"batch/v1\",\n",
    "        \"kind\": \"Job\",\n",
    "        \"spec\": {\n",
    "            \"template\": {\n",
    "                \"metadata\": {\n",
    "                    \"annotations\": {\n",
    "                        \"sidecar.istio.io/inject\": \"false\"\n",
    "                    }\n",
    "                },\n",
    "                \"spec\": {\n",
    "                    \"containers\": [\n",
    "                        {\n",
    "                            \"name\": \"training-container\",\n",
    "                            \"image\": \"yourID/fashion-mnist-retrain:handson.rc4\",\n",
    "                            \"volumeMounts\": [\n",
    "                                {\"name\": \"notebook\", \"mountPath\": \"/notebook\"},\n",
    "                            ],\n",
    "                            \"command\": [\n",
    "                                \"python\",\n",
    "                                \"/app/my_model_retrain.py\",\n",
    "                                \"--node_amount=${trialParameters.epoch}\",\n",
    "                                f\"--dataset_path={new_dataset_path}\",\n",
    "                                f\"--model_path=/notebook/model/{model_version}\",\n",
    "\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \"restartPolicy\": \"Never\",\n",
    "                    \"volumes\": [\n",
    "                        {\"name\": \"notebook\",\n",
    "                         \"persistentVolumeClaim\": {\"claimName\": \"workspace-handson\"}\n",
    "                         }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Configure parameters for the Trial template.\n",
    "    trial_template = V1beta1TrialTemplate(\n",
    "        primary_container_name=\"training-container\",\n",
    "        trial_parameters=[\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"epoch\",\n",
    "                description=\"train epoch\",\n",
    "                reference=\"epoch\"\n",
    "            ),\n",
    "        ],\n",
    "        trial_spec=trial_spec\n",
    "    )\n",
    "\n",
    "    # Experiment object.\n",
    "    experiment = V1beta1Experiment(\n",
    "        api_version=\"kubeflow.org/v1beta1\",\n",
    "        kind=\"Experiment\",\n",
    "        metadata=metadata,\n",
    "        spec=V1beta1ExperimentSpec(\n",
    "            max_trial_count=3,\n",
    "            parallel_trial_count=30,\n",
    "            max_failed_trial_count=3,\n",
    "            algorithm=algorithm_spec,\n",
    "            objective=objective_spec,\n",
    "            parameters=parameters,\n",
    "            resume_policy=None,\n",
    "            trial_template=trial_template,\n",
    "        )\n",
    "    )\n",
    "    kclient.create_experiment(experiment)\n",
    "    accuracy = 0.0\n",
    "    while 1:\n",
    "        time.sleep(60)\n",
    "        status = kclient.get_experiment_status(experiment_name)\n",
    "        result = kclient.get_optimal_hyperparameters(experiment_name)\n",
    "        if status == \"Running\":\n",
    "            print(f\"{experiment_name} is running\")\n",
    "        if status == \"Succeeded\":\n",
    "            if result:\n",
    "                metrics = result['currentOptimalTrial']['observation']['metrics']\n",
    "                val_acc = find_metrics(metrics, objective_metric_name, 'max')\n",
    "            move_dataset(new_dataset_path)                \n",
    "            break\n",
    "\n",
    "    metrics = {\n",
    "        'metrics': [{\n",
    "            'name': 'val-acc',\n",
    "            'numberValue': float(val_acc),\n",
    "            'format': \"PERCENTAGE\",\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    from collections import namedtuple    \n",
    "    result = namedtuple('Outputs', ['mlpipeline_metrics', 'model_version'])    \n",
    "    return result(json.dumps(metrics), model_version)     \n",
    "\n",
    "\n",
    "def disable_cache(op):\n",
    "    op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "\n",
    "def container_op(func):\n",
    "    return func_to_container_op(func,\n",
    "                                base_image=\"dudaji/cap-jupyterlab:tf2.0-cpu\")\n",
    "\n",
    "def train_pipeline(goal_acc: float = 0.50,\n",
    "                   dataset_path: str = \"/notebook/new_dataset/train\"):\n",
    "    notebook_vol = dsl.PipelineVolume(pvc=\"workspace-handson\")\n",
    "\n",
    "    model_op = container_op(get_best_model)\n",
    "    dataset_op = container_op(get_last_dataset)\n",
    "    train_op = container_op(train_from_best_model)\n",
    "\n",
    "    model_comp = model_op(goal_acc) \\\n",
    "        .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "\n",
    "    dataset_comp = dataset_op(dataset_path) \\\n",
    "        .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "\n",
    "    train_comp = train_op(model_version=model_comp.outputs['version'],\n",
    "                          new_dataset_path=dataset_comp.output) \\\n",
    "        .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "                          \n",
    "    disable_cache(dataset_comp)                          \n",
    "    disable_cache(model_comp)                          \n",
    "    disable_cache(train_comp)\n",
    "\n",
    "arguments = {\"goal_acc\": 0.50,\n",
    "             \"dataset_path\": \"/notebook/new_dataset/train\"}\n",
    "\n",
    "client = kfp.Client()\n",
    "client.create_run_from_pipeline_func(train_pipeline, \n",
    "                                     experiment_name=\"train_model\",\n",
    "                                     arguments=arguments)         \n",
    "\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func=train_pipeline,\n",
    "                                package_path='train_pipeline.yaml')    \n",
    "\n",
    "client.upload_pipeline(pipeline_name=\"train_pipeline2\",\n",
    "                       description=\"Train from best model\",\n",
    "                       pipeline_package_path=\"train_pipeline.yaml\")                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b425bec-a556-4e5c-b12c-fa9b122c12bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
