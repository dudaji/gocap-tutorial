{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb84e3b-d0c6-4303-b32c-97cc3c28a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test_pipeline.ipynb\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf    \n",
    "import argparse\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class MyModel(object):\n",
    "    def __init__(self):\n",
    "        self.model_path = None\n",
    "        self.model = None\n",
    "        \n",
    "    def get_model_path(self):\n",
    "        return self.model_path\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def train(self):\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--node_amount', required=False, type=int, default=128)\n",
    "        parser.add_argument('--epoch', required=False, type=int, default=10)\n",
    "        parser.add_argument('--dropout_rate', required=False, type=float, default=0.2)\n",
    "        parser.add_argument('--optimizer', required=False, type=str, default=\"sgd\")\n",
    "        if os.getenv('FAIRING_RUNTIME', None) is None:        \n",
    "            args = parser.parse_args(args=[])\n",
    "        else:            \n",
    "            args = parser.parse_args()\n",
    "        \n",
    "        mnist = tf.keras.datasets.fashion_mnist\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "        print(\"x_test shape:\", x_test.shape, \"y_test shape:\", y_test.shape)\n",
    "\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(args.node_amount, activation='relu'),\n",
    "            tf.keras.layers.Dropout(args.dropout_rate),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        self.model.compile(optimizer=args.optimizer,\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['acc'])\n",
    "\n",
    "\n",
    "        date_folder = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "        if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "            log_dir = \"log/fit/\" + date_folder\n",
    "        else:\n",
    "            log_dir = \"/notebook/log/fit/\" + date_folder \n",
    "\n",
    "        print(f\"tensorboard log dir : {log_dir}\")\n",
    "\n",
    "        tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                        histogram_freq=1)\n",
    "        print(f\"Total epochs {args.epoch}\")\n",
    "        hist = self.model.fit(x_train, y_train,\n",
    "                              verbose=0,\n",
    "                              validation_data=(x_test, y_test),\n",
    "                              epochs=args.epoch,\n",
    "                              callbacks=[LoggingTrain(),\n",
    "                                         tensorboard_cb])\n",
    "        model_ver = get_strftime('%Y%m%d%H%M%S') # timestamp 형식 변경 (문자 제거)\n",
    "        model_val_acc = int(float(hist.history['val_acc'][-1]) * 100) # 소수점 제거\n",
    "        self.model_path = f\"model/{model_ver}.{model_val_acc}\"\n",
    "        self.model.save(self.model_path, save_format='tf')\n",
    "        return self.model\n",
    "    \n",
    "def get_strftime(time_format):\n",
    "    dt_now = datetime.datetime.now()\n",
    "    return dt_now.strftime(time_format)        \n",
    "\n",
    "def p(msg):\n",
    "    dt_now = datetime.datetime.now()\n",
    "    strftime = dt_now.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    print(f\"{strftime} {msg}\", flush=True)    \n",
    "    \n",
    "class LoggingTrain(Callback):\n",
    "    \"\"\"logging for train\n",
    "    \"\"\"\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if batch % 100 == 0:\n",
    "            p(f\"batch: {batch}\")\n",
    "            p(f\"accuracy={logs.get('acc')} loss={logs.get('loss')}\")\n",
    "            \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        p(f\"epoch: {epoch}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        p(f\"Validation-accuracy={logs.get('val_acc')}\")\n",
    "        p(f\"Validation-loss={logs.get('val_loss')}\")\n",
    "        return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a77885-66b9-47a7-ba06-b3f8e6f83284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test_pipeline.ipynb\n",
    "my_model = MyModel()\n",
    "model = my_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190615f-5350-4583-a135-17bf7a027e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test_pipeline.ipynb\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op, OutputPath\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "def test_model_component(model_version: str) -> NamedTuple('Outputs', [\n",
    "    ('mlpipeline_metrics', 'Metrics'),\n",
    "]):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import json\n",
    "    test_dataset = np.load(\"/notebook/new_dataset/test/new_test.npz\")\n",
    "    x_test = test_dataset['x_test']\n",
    "    y_test = test_dataset['y_test']\n",
    "    loaded_model = tf.keras.models.load_model(f\"/notebook/model/{model_version}\")\n",
    "    score = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"test-accuracy = {score[1]}, test-loss={score[0]}\")\n",
    "\n",
    "    metrics = {\n",
    "        'metrics': [{\n",
    "            'name': 'val-acc',\n",
    "            'numberValue': float(round(score[1], 4)),\n",
    "            'format': \"PERCENTAGE\",\n",
    "        }, {\n",
    "            'name': 'val-loss',\n",
    "            'numberValue': float(round(score[0], 4)),\n",
    "            'format': \"RAW\",\n",
    "        }, {\n",
    "            'name': 'model-version',\n",
    "            'numberValue': float(model_version),\n",
    "            'format': \"RAW\",\n",
    "        }] \n",
    "    }\n",
    "    \n",
    "    from collections import namedtuple    \n",
    "    result = namedtuple(\n",
    "      'Outputs',\n",
    "      ['mlpipeline_metrics'])    \n",
    "    return result(json.dumps(metrics))\n",
    "\n",
    "\n",
    "def test_model_pipeline(model_version: str):\n",
    "    test_model_op = func_to_container_op(test_model_component,\n",
    "                                     base_image=\"dudaji/cap-jupyterlab:tf2.0-cpu\") \n",
    "\n",
    "    notebook_vol = dsl.PipelineVolume(pvc=\"workspace-handson\")\n",
    "    test_model = test_model_op(model_version) \\\n",
    "        .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "    test_model.execution_options.caching_strategy.max_cache_staleness = \"P0D\"    \n",
    "    \n",
    "\n",
    "\n",
    "arguments = {'model_version': \"20210812034159.85\"}\n",
    "\n",
    "client = kfp.Client()\n",
    "client.create_run_from_pipeline_func(test_model_pipeline, \n",
    "                                     experiment_name=\"tutorial_model\",\n",
    "                                     arguments=arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5206f-f2ba-49bf-b8fe-b9473f487d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(pipeline_func=test_model_pipeline,\n",
    "                                package_path='test_model_pipeline.yaml')\n",
    "\n",
    "client.upload_pipeline(pipeline_name=\"test-model-pipeline\",\n",
    "                       pipeline_package_path=\"test_model_pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc55281-89cb-44fc-9aca-5e85a9aa8fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
