{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d7893-5ee2-465e-8a1b-5e714566ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test_pipeline.ipynb\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf    \n",
    "import argparse\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class MyModel(object):\n",
    "    def __init__(self):\n",
    "        self.model_path = None\n",
    "        self.model = None\n",
    "        \n",
    "    def get_model_path(self):\n",
    "        return self.model_path\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def train(self):\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--node_amount', required=False, type=int, default=128)\n",
    "        parser.add_argument('--epoch', required=False, type=int, default=10)\n",
    "        parser.add_argument('--dropout_rate', required=False, type=float, default=0.2)\n",
    "        parser.add_argument('--optimizer', required=False, type=str, default=\"sgd\")\n",
    "        parser.add_argument('--dataset_path', required=False, type=str, default=None)\n",
    "        parser.add_argument('--model_path', required=False, type=str, default=None)\n",
    "        parser.add_argument('--train_version', required=False, type=str, default=None)                 \n",
    "        parser.add_argument('--save_version', required=False, type=str, default=None) \n",
    "        if os.getenv('FAIRING_RUNTIME', None) is None:        \n",
    "            args = parser.parse_args(args=[])\n",
    "        else:            \n",
    "            args = parser.parse_args()\n",
    "        \n",
    "        if args.dataset_path is not None:\n",
    "            new_dataset = np.load(args.dataset_path)\n",
    "            new_x = new_dataset['x_train']\n",
    "            new_y = new_dataset['y_train']\n",
    "\n",
    "            add_x_train, add_x_test, \\\n",
    "            add_y_train, add_y_test = train_test_split(new_x, new_y, \n",
    "                                                   test_size=0.1,\n",
    "                                                   random_state=42)\n",
    "            train_size = len(add_y_train)\n",
    "            test_size = len(add_y_test)\n",
    "            x_train = np.append(x_train[:train_size], add_x_train, axis=0)\n",
    "            x_test = np.append(x_test[:test_size], add_x_test, axis=0)\n",
    "            y_train = np.append(y_train[:train_size], add_y_train, axis=0)   \n",
    "            y_test = np.append(y_test[:test_size], add_y_test, axis=0)   \n",
    "        \n",
    "        if args.model_path is None:\n",
    "            self.model = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                tf.keras.layers.Dense(args.node_amount, activation='relu'),\n",
    "                tf.keras.layers.Dropout(args.dropout_rate),\n",
    "                tf.keras.layers.Dense(10, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            self.model.compile(optimizer=args.optimizer,\n",
    "                               loss='sparse_categorical_crossentropy',\n",
    "                               metrics=['acc'])\n",
    "        else:\n",
    "            self.model = tf.keras.models.load_model(args.model_path)  \n",
    "        \n",
    "        mnist = tf.keras.datasets.fashion_mnist\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "        print(\"x_test shape:\", x_test.shape, \"y_test shape:\", y_test.shape)\n",
    "\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(args.node_amount, activation='relu'),\n",
    "            tf.keras.layers.Dropout(args.dropout_rate),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        self.model.compile(optimizer=args.optimizer,\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['acc'])\n",
    "\n",
    "\n",
    "        date_folder = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "        if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "            log_dir = \"log/fit/\" + date_folder\n",
    "        else:\n",
    "            log_dir = \"/notebook/log/fit/\" + date_folder \n",
    "\n",
    "        print(f\"tensorboard log dir : {log_dir}\")\n",
    "\n",
    "        tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                                        histogram_freq=1)\n",
    "        print(f\"Total epochs {args.epoch}\")\n",
    "        hist = self.model.fit(x_train, y_train,\n",
    "                              verbose=0,\n",
    "                              validation_data=(x_test, y_test),\n",
    "                              epochs=args.epoch,\n",
    "                              callbacks=[LoggingTrain(),\n",
    "                                         tensorboard_cb])\n",
    "        \n",
    "        model_ver = get_strftime('%Y%m%d%H%M%S') # timestamp 형식 변경 (문자 제거)\n",
    "        if args.save_version is None:\n",
    "            model_ver = get_strftime('%Y%m%d%H%M%S')\n",
    "        else: \n",
    "            model_ver = args.save_version \n",
    "        model_val_acc = int(float(hist.history['val_acc'][-1]) * 100)\n",
    "        self.model_version = f\"{model_ver}.{model_val_acc}\"\n",
    "        save_model_path = f\"{args.model_path}/{self.model_version}\"\n",
    "        self.model.save(save_model_path, save_format='tf')                      \n",
    "        return self.model\n",
    "    \n",
    "def get_strftime(time_format):\n",
    "    dt_now = datetime.datetime.now()\n",
    "    return dt_now.strftime(time_format)        \n",
    "\n",
    "def p(msg):\n",
    "    dt_now = datetime.datetime.now()\n",
    "    strftime = dt_now.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    print(f\"{strftime} {msg}\", flush=True)    \n",
    "    \n",
    "class LoggingTrain(Callback):\n",
    "    \"\"\"logging for train\n",
    "    \"\"\"\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if batch % 100 == 0:\n",
    "            p(f\"batch: {batch}\")\n",
    "            p(f\"accuracy={logs.get('acc')} loss={logs.get('loss')}\")\n",
    "            \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        p(f\"epoch: {epoch}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        p(f\"Validation-accuracy={logs.get('val_acc')}\")\n",
    "        p(f\"Validation-loss={logs.get('val_loss')}\")\n",
    "        return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ccc08-be62-40c0-97fe-cbd580aff17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kubeflow.fairing.builders.append.append import AppendBuilder\n",
    "from kubeflow.fairing.preprocessors.converted_notebook import ConvertNotebookPreprocessor\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        \n",
    "        preprocessor = ConvertNotebookPreprocessor(notebook_file=\"my_model_retrain.ipynb\")\n",
    "\n",
    "        DOCKER_REGISTRY = \"ydh0924\"\n",
    "        base_image = \"dudaji/cap-jupyterlab:tf2.0-cpu\"\n",
    "        image_name = \"fashion-mnist-retrain\"\n",
    "        image_tag = \"handson\"\n",
    "\n",
    "        builder = AppendBuilder(registry=DOCKER_REGISTRY,\n",
    "                                image_name=image_name,\n",
    "                                base_image=base_image,\n",
    "                                tag=image_tag,\n",
    "                                preprocessor=preprocessor,\n",
    "                                push=True)\n",
    "        image_name = builder.build()\n",
    "        print(image_name)\n",
    "\n",
    "    else:\n",
    "        remote_model = MyModel()\n",
    "        remote_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80001b5d-d9e5-472a-b3e3-3efdb5d9c4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
