{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849ca4d-ade1-4b92-ae9d-f2288ab60003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_data_pipeline.ipynb\n",
    "def count_raw_images(raw_path: str) -> int:\n",
    "    import fnmatch\n",
    "    import os\n",
    "    return len(fnmatch.filter(os.listdir(raw_path), '*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce95ac2-5936-42f1-a931-c5315ac033d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_data_pipeline.ipynb\n",
    "def preprocess_raw_images(raw_path: str,\n",
    "                          save_path: str,\n",
    "                          size: int = 1000) -> int:\n",
    "    import datetime\n",
    "    import fnmatch\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from PIL import Image\n",
    "\n",
    "    img_rows, img_cols = 28, 28\n",
    "\n",
    "    files = fnmatch.filter(os.listdir(raw_path), '*.png')\n",
    "    files.sort(key=lambda fn: os.path.getmtime(os.path.join(raw_path, fn)))\n",
    "    target_files = files[:size].copy()\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i, name in enumerate(target_files):\n",
    "        img = Image.open(os.path.join(raw_path, name))\n",
    "        img_array = np.array(img)\n",
    "        x_train.append(img_array.reshape(img_rows, img_cols))\n",
    "        y_train.append(int(name[0]))\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    # Save numpy arr to npz\n",
    "    date_postfix = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    npz_name = f\"{date_postfix}-{size}.npz\"\n",
    "    npz_save_path = f\"{save_path}/{npz_name}\"\n",
    "    np.savez(npz_save_path, x_train=x_train, y_train=y_train)\n",
    "    \n",
    "    # delete image \n",
    "    for i, name in enumerate(target_files):\n",
    "        file_path = os.path.join(raw_path, name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path) \n",
    "    \n",
    "    return npz_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df8e9a-e52e-4e6d-be09-5281fdf49aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_data_pipeline.ipynb\n",
    "print(preprocess_raw_images(\"new_dataset/raw\", \"new_dataset/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2df48-5f04-4281-8a89-9889d179c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_data_pipeline.ipynb\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op\n",
    "\n",
    "def disable_cache(op):\n",
    "    op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"  \n",
    "\n",
    "def preprocess_data_pipeline(raw_path: str = \"/notebook/new_dataset/raw\", \n",
    "                             save_path: str = \"/notebook/new_dataset/train\", \n",
    "                             size: int = 1000):\n",
    "    \n",
    "    notebook_vol = dsl.PipelineVolume(pvc=\"workspace-handson\")\n",
    "    count_op = func_to_container_op(count_raw_images) \n",
    "    preprocess_op = func_to_container_op(preprocess_raw_images,\n",
    "                                         packages_to_install=[\"numpy\", \"pillow\"]) \n",
    "    \n",
    "    count = count_op(raw_path).add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "    disable_cache(count)\n",
    "    with dsl.Condition(count.output > size):\n",
    "        preprocess = preprocess_op(raw_path, save_path, size) \\\n",
    "            .add_pvolumes(pvolumes={\"/notebook\": notebook_vol})\n",
    "        disable_cache(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd630518-836e-4f34-9bae-8b00abe651ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_data_pipeline.ipynb\n",
    "arguments = {\"raw_path\": \"/notebook/new_dataset/raw\",\n",
    "             \"save_path\": \"/notebook/new_dataset/train\"}\n",
    "\n",
    "client = kfp.Client()\n",
    "client.create_run_from_pipeline_func(preprocess_data_pipeline, \n",
    "                                     experiment_name=\"preprocessed_data\",\n",
    "                                     arguments=arguments)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e466ac-bcba-4e85-8a30-567b37e03f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_data_pipeline.ipynb\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=preprocess_data_pipeline,\n",
    "    package_path='preprocess_data_pipeline.yaml')\n",
    "\n",
    "client.upload_pipeline(pipeline_name=\"preprocess_data_pipeline\",\n",
    "                       description=\"Convert raw images to npz\",\n",
    "                       pipeline_package_path=\"preprocess_data_pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1f790-a7f0-40ba-8653-57b9aaa7aab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
